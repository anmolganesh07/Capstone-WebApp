# -*- coding: utf-8 -*-
"""capstone_backend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LkzBTRm1tuBjW340t98rmZeoyRNtoz76
"""


import nltk 
from googletrans import Translator
nltk.download("stopwords")
nltk.download('punkt')

"""IMPORT"""

from easyocr import Reader
import PyPDF2
from PyPDF2 import PdfReader
import fitz
from nltk.corpus import stopwords
from nltk.cluster.util import cosine_distance
import numpy as np
import networkx as nx
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from heapq import nlargest
from flask import Flask, render_template

"""INITIALIZATIONS"""

picture = "kannada.png"
pdf = "arabic_text.pdf"

"""IMAGE EXTRACTION"""

# Load model for multiple languages 
reader_en_fr = Reader(['en', 'fr','es'])
#reader_ta_en = Reader(['en','ta'])
reader_te_en = Reader(['en','te'])
reader_kn_en = Reader(['en','kn'])
reader_hi_en = Reader(['en','hi'])
reader_ch = Reader(['ch_sim'])
reader_ar = Reader(['ar'])

def read_text(image_name, model_name, in_line=True):
    # Read the data
    text = model_name.readtext(image_name, detail=0, paragraph=in_line)
    # Join texts writing each text in new line
    return '\n'.join(text)

ka_text = read_text(picture, reader_kn_en)
print(ka_text)

ch_text = read_text("chinese.jpg", reader_ch)
print(ch_text)

# ar_text = read_text("arabic.png", reader_ar)
# print(ar_text)

"""TO READ PDF"""

# Open the PDF file in read-binary mode
def pdf_read():
    try:
        with open(pdf, 'rb') as pdf_file:
            # Create a PyPDF2 PdfFileReader object to read the PDF
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            # Read all the pages of the PDF and store the text in a variable
            text = ''
            for page_num in range(len(pdf_reader.pages)):
                page = pdf_reader.pages[page_num]
                text += page.extract_text()
            return text
    except FileNotFoundError:
        print(f"Error: The file {pdf} was not found.")
        return ""

pdf_text = pdf_read()

"""TRANSLATION"""

async def translate_text(text, lang):
    translator = Translator()
    translated_text = await translator.translate(text, dest='en')
    return translated_text.text


"""SUMMARIZE"""

def summarize(txt, n):
    # Tokenize the text into sentences and words
    sentences = sent_tokenize(txt)
    words = word_tokenize(txt)
    
    # Remove stop words from the words list
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word.lower() not in stop_words]
    
    # Calculate the frequency of each word
    freq = nltk.FreqDist(words)
    
    # Calculate the score of each sentence
    scores = {}
    for i, sentence in enumerate(sentences):
        for word in word_tokenize(sentence.lower()):
            if word in freq:
                if i not in scores:
                    scores[i] = freq[word]
                else:
                    scores[i] += freq[word]
                    
    # Get the top n sentences with the highest scores
    top_sentences = nlargest(n, scores, key=scores.get)
    
    # Sort the top sentences in the order they appear in the original text
    summary = ' '.join([sentences[i] for i in sorted(top_sentences)])
    return summary

async def main():
    """MAIN EXECUTION"""
    # Initialize translation
    translated_text = await translate_text(pdf_text, 'auto')
    summary = summarize(translated_text, 40)
    print(summary)
    
    """DESIRED CONVERSION """
    translated_text1 = await translate_text(summary, 'fr')
    print(translated_text1)

    """SAVE OUTPUT AS TXT OF SUMMARIZATION"""
    with open('output.txt', 'w') as f:
        f.write(translated_text)
    print("Output saved to output.txt")

    print("You can save the output to the dashboard")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
